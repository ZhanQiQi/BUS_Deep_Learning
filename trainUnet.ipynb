{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import *\n",
    "from res_unet import *\n",
    "from data import *\n",
    "import os\n",
    "import h5py\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128,128)\n",
    "# model = unet(batchnorm = False, input_size=input_shape+(1,))\n",
    "model = res_unet(batchnorm = False, input_size=input_shape+(1,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'res_unet_bus_base_w_normals_aug'\n",
    "# plot_model(model, to_file='model_architectures/{}.png'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Unet with bus data\n",
    "\n",
    "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "train_image_path = 'data/seg_dir/train_images'\n",
    "train_mask_path = 'data/seg_dir/train_masks'\n",
    "len_training_set = len(os.listdir(train_image_path))\n",
    "print('len training set -->', len_training_set)\n",
    "\n",
    "#Validation Data\n",
    "val_image_path = 'data/seg_dir/val_images'\n",
    "val_mask_path = 'data/seg_dir/val_masks'\n",
    "len_val_set = len(os.listdir(val_image_path))\n",
    "print('len validation set -->', len_val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = 'on'\n",
    "\n",
    "imgs_train,imgs_mask_train = train_generator_npy(input_shape, train_image_path, train_mask_path,'','')\n",
    "imgs_val,imgs_mask_val = train_generator_npy(input_shape, val_image_path, val_mask_path,'','')\n",
    "seed = 1\n",
    "\n",
    "#Training Data\n",
    "train_batch_size = 16\n",
    "\n",
    "data_gen_args = dict(width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    shear_range=10,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "if aug == 'on':\n",
    "    train_image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    train_mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "else:\n",
    "    train_image_datagen = ImageDataGenerator()\n",
    "    train_mask_datagen = ImageDataGenerator()\n",
    "\n",
    "train_image_generator = train_image_datagen.flow(imgs_train, batch_size=train_batch_size, seed=seed) #save_to_dir='/external_drive/BUS_Deep_Learning/data/seg_dir_nn_unet/train_aug_images'\n",
    "train_mask_generator = train_mask_datagen.flow(imgs_mask_train, batch_size=train_batch_size, seed=seed) #save_to_dir='/external_drive/BUS_Deep_Learning/data/seg_dir_nn_unet/train_aug_masks'\n",
    "\n",
    "tsg = zip(train_image_generator, train_mask_generator)\n",
    "\n",
    "#Validation Data\n",
    "\n",
    "val_batch_size = 16\n",
    "\n",
    "val_image_datagen = ImageDataGenerator()\n",
    "val_mask_datagen = ImageDataGenerator()\n",
    "\n",
    "val_image_generator = train_image_datagen.flow(imgs_val, batch_size=val_batch_size, seed=seed)\n",
    "val_mask_generator = train_mask_datagen.flow(imgs_mask_val, batch_size=val_batch_size, seed=seed)\n",
    "\n",
    "vsg = zip(val_image_generator, val_mask_generator)\n",
    "\n",
    "# # Final Generators\n",
    "# tsg = convert_mask_generator(tsg)\n",
    "# vsg = convert_mask_generator(vsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'trained_models'\n",
    "model_checkpoint = ModelCheckpoint(model_dir+'/'+model_name+'.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\n",
    "history = model.fit_generator(tsg, validation_data = vsg, steps_per_epoch=len_training_set/16, validation_steps=len_val_set/16,\n",
    "                    epochs=50,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_dir+'/'+'{}_history.hdf5'.format(model_name)) as hfile:\n",
    "    for keyi in history.history:\n",
    "        hfile.create_dataset(keyi, data=history.history[keyi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
